#include "db_common.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>

typedef struct {
    const char *topic;
    const char *category;
    int difficulty;
    const char *content;
} LessonData;

// Comprehensive 2024-2025 Systems Programming Lessons
LessonData lessons[] = {
    // Database Internals
    {
        "B+ Tree Indexing in Modern Databases",
        "Database Internals",
        DIFFICULTY_ADVANCED,
        "B+ trees are the backbone of modern database indexes. Unlike B-trees, B+ trees store all data in leaf nodes, making range queries more efficient.\n\n"
        "Key Properties (2024 optimizations):\n"
        "- All leaf nodes are linked for efficient sequential access\n"
        "- Internal nodes only store keys, maximizing fanout\n"
        "- Modern implementations use SIMD for key comparisons\n"
        "- Cache-conscious layouts reduce CPU cache misses\n\n"
        "Example: PostgreSQL uses B+ trees with a typical fanout of 300-400.\n"
        "In 2024, databases like RocksDB use LSM trees for write-heavy workloads.\n\n"
        "Implementation tip: Use SIMD instructions (AVX-512) for parallel key comparisons:\n"
        "```c\n"
        "__m512i keys = _mm512_loadu_si512(node->keys);\n"
        "__m512i search = _mm512_set1_epi32(key);\n"
        "__mmask16 mask = _mm512_cmpgt_epi32_mask(keys, search);\n"
        "```"
    },
    {
        "MVCC: Multi-Version Concurrency Control",
        "Database Internals",
        DIFFICULTY_EXPERT,
        "MVCC allows multiple transactions to access the same data concurrently without locking, by maintaining multiple versions of each row.\n\n"
        "Modern MVCC Implementations (2024):\n\n"
        "PostgreSQL approach:\n"
        "- Each row has xmin (creation txn) and xmax (deletion txn) fields\n"
        "- Vacuum process cleans up old versions\n"
        "- Visibility rules determine which version a transaction sees\n\n"
        "MySQL InnoDB approach:\n"
        "- Uses undo logs to reconstruct old versions\n"
        "- More space-efficient but slower for read-heavy workloads\n\n"
        "2024 Optimization: Snapshot isolation with temporal indexes for efficient historical queries.\n\n"
        "Challenge: Implementing MVCC requires careful handling of:\n"
        "- Transaction ID wraparound (solved with epoch-based IDs)\n"
        "- Version chain bloat (mitigated with aggressive vacuum)\n"
        "- Read-only transaction optimization (using snapshot timestamps)"
    },
    {
        "LSM Trees vs B-Trees: Modern Trade-offs",
        "Database Internals",
        DIFFICULTY_ADVANCED,
        "Log-Structured Merge (LSM) trees have become dominant for write-heavy workloads in 2024.\n\n"
        "LSM Tree Architecture:\n"
        "- Writes go to in-memory memtable (SkipList or B-tree)\n"
        "- Flushed to immutable SSTables on disk\n"
        "- Background compaction merges SSTables\n"
        "- Bloom filters reduce read amplification\n\n"
        "2024 Innovations:\n"
        "- Tiered compaction strategies (Cassandra, ScyllaDB)\n"
        "- Partitioned indexes to reduce write amplification\n"
        "- NVMe-optimized SSTable formats with direct I/O\n\n"
        "When to use LSM trees:\n"
        "- Write-heavy workloads (logs, metrics, time-series)\n"
        "- Sequential reads are common\n"
        "- Storage space is abundant\n\n"
        "When to use B-trees:\n"
        "- Read-heavy workloads\n"
        "- Random access patterns\n"
        "- Predictable latency requirements\n\n"
        "Example: RocksDB (LSM) vs PostgreSQL (B-tree)"
    },
    {
        "Query Optimization: Cost-Based vs Rule-Based",
        "Database Internals",
        DIFFICULTY_INTERMEDIATE,
        "Modern query optimizers use sophisticated cost models to choose the best execution plan.\n\n"
        "Cost-Based Optimization (CBO):\n"
        "1. Generate multiple query plans\n"
        "2. Estimate cost using statistics (cardinality, selectivity)\n"
        "3. Choose the plan with minimum estimated cost\n\n"
        "2024 Advanced Techniques:\n"
        "- ML-based cardinality estimation (PostgreSQL 17, Google F1)\n"
        "- Adaptive query execution (Spark 3.x, SQL Server)\n"
        "- Runtime plan selection based on actual data distribution\n\n"
        "Statistics that matter:\n"
        "- Row count (n_live_tup)\n"
        "- Column histograms (for skewed data)\n"
        "- Correlation between columns\n"
        "- Index selectivity\n\n"
        "Pro tip: Use EXPLAIN ANALYZE to compare estimated vs actual costs.\n\n"
        "Modern trend: Vectorized execution engines (DuckDB, ClickHouse) for 10-100x speedups on analytical queries."
    },

    // Security
    {
        "Memory-Safe Systems Programming with Rust",
        "Security",
        DIFFICULTY_INTERMEDIATE,
        "Rust eliminates memory safety bugs at compile time through its ownership system, making it ideal for systems programming in 2024.\n\n"
        "Key Security Features:\n\n"
        "1. Ownership & Borrowing:\n"
        "   - Each value has exactly one owner\n"
        "   - References are checked at compile time\n"
        "   - No data races in safe Rust\n\n"
        "2. No Null Pointer Derefs:\n"
        "   ```rust\n"
        "   let x: Option<i32> = Some(5);\n"
        "   match x {\n"
        "       Some(val) => println!(\"{}\", val),\n"
        "       None => println!(\"No value\"),\n"
        "   }\n"
        "   ```\n\n"
        "3. Bounds Checking:\n"
        "   - All array accesses are checked\n"
        "   - Panics instead of buffer overflows\n\n"
        "2024 Industry Adoption:\n"
        "- Linux kernel (Rust for drivers)\n"
        "- Windows (Rust in kernel components)\n"
        "- AWS (Firecracker, Bottlerocket)\n"
        "- Google (Android, Fuchsia)\n\n"
        "Migration strategy: Gradually replace C components with Rust using FFI."
    },
    {
        "Side-Channel Attacks and Mitigations",
        "Security",
        DIFFICULTY_EXPERT,
        "Side-channel attacks exploit information leaked through physical implementation of cryptographic systems.\n\n"
        "Common Side Channels (2024):\n\n"
        "1. Timing Attacks:\n"
        "   - String comparison using memcmp() can leak length\n"
        "   - Solution: Constant-time comparison\n\n"
        "   ```c\n"
        "   int secure_compare(const char *a, const char *b, size_t len) {\n"
        "       volatile unsigned char result = 0;\n"
        "       for (size_t i = 0; i < len; i++) {\n"
        "           result |= a[i] ^ b[i];\n"
        "       }\n"
        "       return result;\n"
        "   }\n"
        "   ```\n\n"
        "2. Cache Timing (Spectre/Meltdown):\n"
        "   - Speculative execution leaks data\n"
        "   - Mitigation: LFENCE instructions, retpolines\n\n"
        "3. Power Analysis:\n"
        "   - Power consumption reveals secret keys\n"
        "   - Mitigation: Masking, constant-time algorithms\n\n"
        "2024 Best Practices:\n"
        "- Use libsodium for crypto (resistant to timing attacks)\n"
        "- Enable CPU mitigations (IBRS, STIBP)\n"
        "- Audit code with tools like ctgrind, dudect\n"
        "- Use Intel SGX or ARM TrustZone for sensitive operations"
    },
    {
        "Modern Authentication: OAuth 2.1 and WebAuthn",
        "Security",
        DIFFICULTY_INTERMEDIATE,
        "2024 authentication best practices emphasize passwordless auth and secure token handling.\n\n"
        "OAuth 2.1 (2024 standard):\n"
        "- Mandates PKCE for all clients\n"
        "- Deprecates implicit flow\n"
        "- Requires HTTPS for all endpoints\n"
        "- Recommends short-lived access tokens (15 min)\n\n"
        "PKCE Flow:\n"
        "1. Client generates code_verifier (random string)\n"
        "2. Computes code_challenge = SHA256(code_verifier)\n"
        "3. Authorization request includes code_challenge\n"
        "4. Token request includes code_verifier\n"
        "5. Server verifies SHA256(code_verifier) == code_challenge\n\n"
        "WebAuthn (FIDO2):\n"
        "- Public key cryptography for authentication\n"
        "- Phishing-resistant (domain binding)\n"
        "- Supported by all major browsers (2024)\n\n"
        "Implementation:\n"
        "```javascript\n"
        "const credential = await navigator.credentials.create({\n"
        "    publicKey: {\n"
        "        challenge: new Uint8Array(32),\n"
        "        rp: { name: \"Example\" },\n"
        "        user: { id, name, displayName },\n"
        "        pubKeyCredParams: [{ type: 'public-key', alg: -7 }]\n"
        "    }\n"
        "});\n"
        "```\n\n"
        "Industry trend: Passkeys (Apple, Google, Microsoft) for consumer auth."
    },
    {
        "Container Security: Isolation and Hardening",
        "Security",
        DIFFICULTY_ADVANCED,
        "Containers provide isolation but require careful hardening for production use in 2024.\n\n"
        "Linux Security Mechanisms:\n\n"
        "1. Namespaces (isolation):\n"
        "   - PID: Process isolation\n"
        "   - Network: Separate network stack\n"
        "   - Mount: Filesystem isolation\n"
        "   - User: UID/GID mapping\n\n"
        "2. Cgroups (resource limits):\n"
        "   ```bash\n"
        "   cgcreate -g cpu,memory:myapp\n"
        "   cgset -r cpu.cfs_quota_us=100000 myapp\n"
        "   cgset -r memory.limit_in_bytes=1G myapp\n"
        "   ```\n\n"
        "3. Seccomp (syscall filtering):\n"
        "   - Restrict container to ~50 allowed syscalls\n"
        "   - Docker default profile blocks ~300 dangerous calls\n\n"
        "4. AppArmor/SELinux (MAC):\n"
        "   - Mandatory access control\n"
        "   - Prevents container breakout\n\n"
        "2024 Best Practices:\n"
        "- Run containers as non-root (USER directive)\n"
        "- Use distroless images (gcr.io/distroless)\n"
        "- Scan images for vulnerabilities (Trivy, Grype)\n"
        "- Enable user namespaces (userns-remap)\n"
        "- Use gVisor or Kata Containers for untrusted workloads\n\n"
        "Example Docker hardening:\n"
        "```dockerfile\n"
        "FROM gcr.io/distroless/static-debian12\n"
        "USER 65534:65534\n"
        "COPY --chown=65534:65534 app /app\n"
        "CMD [\"/app\"]\n"
        "```"
    },

    // Networking
    {
        "Zero-Copy Networking with io_uring",
        "Networking",
        DIFFICULTY_ADVANCED,
        "io_uring is a modern Linux async I/O interface that enables zero-copy networking and eliminates syscall overhead.\n\n"
        "Traditional I/O problems:\n"
        "- Each operation requires a syscall (context switch)\n"
        "- epoll/select require separate syscalls\n"
        "- Multiple data copies (user space <-> kernel space)\n\n"
        "io_uring advantages (2024):\n"
        "- Shared ring buffers between kernel and user space\n"
        "- Batch multiple operations\n"
        "- Zero-copy with registered buffers\n"
        "- Polling mode for ultra-low latency\n\n"
        "Basic usage:\n"
        "```c\n"
        "struct io_uring ring;\n"
        "io_uring_queue_init(256, &ring, 0);\n\n"
        "struct io_uring_sqe *sqe = io_uring_get_sqe(&ring);\n"
        "io_uring_prep_read(sqe, fd, buf, len, offset);\n"
        "io_uring_submit(&ring);\n\n"
        "struct io_uring_cqe *cqe;\n"
        "io_uring_wait_cqe(&ring, &cqe);\n"
        "// process result\n"
        "io_uring_cqe_seen(&ring, cqe);\n"
        "```\n\n"
        "2024 Performance gains:\n"
        "- 50-80% reduction in CPU usage vs epoll\n"
        "- 2-3x throughput for small I/O operations\n"
        "- Used in: PostgreSQL 16+, Redis 7+, nginx\n\n"
        "Pro tip: Combine with IORING_SETUP_SQPOLL for kernel-side polling."
    },
    {
        "HTTP/3 and QUIC: The Future of Web",
        "Networking",
        DIFFICULTY_INTERMEDIATE,
        "HTTP/3 uses QUIC (UDP-based) instead of TCP, solving head-of-line blocking and improving performance.\n\n"
        "Why HTTP/3 in 2024:\n\n"
        "1. No Head-of-Line Blocking:\n"
        "   - TCP: One lost packet blocks all streams\n"
        "   - QUIC: Independent streams, loss only affects one stream\n\n"
        "2. Faster Connection Establishment:\n"
        "   - TCP+TLS: 3 RTTs (SYN, TLS handshake)\n"
        "   - QUIC: 1 RTT (combined handshake)\n"
        "   - 0-RTT for resumed connections\n\n"
        "3. Connection Migration:\n"
        "   - Switch networks (WiFi -> 4G) without reconnecting\n"
        "   - Connection ID survives IP changes\n\n"
        "4. Built-in Encryption:\n"
        "   - TLS 1.3 integrated into QUIC\n"
        "   - All packets encrypted (except first)\n\n"
        "Performance in 2024:\n"
        "- 20-40% faster page loads on lossy networks\n"
        "- 70% of Google traffic uses HTTP/3\n"
        "- Cloudflare reports 5-10% faster median load times\n\n"
        "Implementation libraries:\n"
        "- quiche (Cloudflare, Rust)\n"
        "- lsquic (LiteSpeed, C)\n"
        "- msquic (Microsoft, C)\n\n"
        "Challenge: UDP may be blocked by some firewalls, requires fallback to HTTP/2."
    },
    {
        "eBPF: Programmable Networking in the Kernel",
        "Networking",
        DIFFICULTY_EXPERT,
        "eBPF allows running sandboxed programs in the Linux kernel without modifying kernel code or loading modules.\n\n"
        "Use cases in 2024:\n\n"
        "1. Network Observability:\n"
        "   - Trace every packet without copying to user space\n"
        "   - Tools: Cilium, Katran, Hubble\n\n"
        "2. Load Balancing:\n"
        "   - XDP (eXpress Data Path) for wire-speed packet processing\n"
        "   - Process packets before kernel stack\n"
        "   - 10M+ packets/second per core\n\n"
        "3. Security:\n"
        "   - Drop malicious packets at driver level\n"
        "   - DDoS mitigation with minimal overhead\n\n"
        "Example XDP program (blocks port 80):\n"
        "```c\n"
        "SEC(\"xdp\")\n"
        "int xdp_drop_port80(struct xdp_md *ctx) {\n"
        "    void *data_end = (void *)(long)ctx->data_end;\n"
        "    void *data = (void *)(long)ctx->data;\n"
        "    \n"
        "    struct ethhdr *eth = data;\n"
        "    if ((void *)(eth + 1) > data_end) return XDP_PASS;\n"
        "    \n"
        "    if (eth->h_proto != htons(ETH_P_IP)) return XDP_PASS;\n"
        "    \n"
        "    struct iphdr *ip = (void *)(eth + 1);\n"
        "    if ((void *)(ip + 1) > data_end) return XDP_PASS;\n"
        "    \n"
        "    if (ip->protocol != IPPROTO_TCP) return XDP_PASS;\n"
        "    \n"
        "    struct tcphdr *tcp = (void *)(ip + 1);\n"
        "    if ((void *)(tcp + 1) > data_end) return XDP_PASS;\n"
        "    \n"
        "    if (tcp->dest == htons(80)) return XDP_DROP;\n"
        "    \n"
        "    return XDP_PASS;\n"
        "}\n"
        "```\n\n"
        "2024 Tooling:\n"
        "- libbpf (C library)\n"
        "- libbpf-rs (Rust bindings)\n"
        "- bpftool (debugging)\n\n"
        "Industry adoption: Facebook, Netflix, Google use eBPF for production networking."
    },
    {
        "gRPC and Protocol Buffers: Modern RPC",
        "Networking",
        DIFFICULTY_INTERMEDIATE,
        "gRPC is a high-performance RPC framework using Protocol Buffers, ideal for microservices in 2024.\n\n"
        "Advantages over REST:\n\n"
        "1. Performance:\n"
        "   - Binary protocol (vs JSON text)\n"
        "   - HTTP/2 multiplexing\n"
        "   - 7-10x smaller payloads\n"
        "   - 5-8x faster serialization\n\n"
        "2. Streaming:\n"
        "   - Bidirectional streaming\n"
        "   - Server push\n"
        "   - Real-time updates\n\n"
        "3. Type Safety:\n"
        "   - Schema-first design\n"
        "   - Code generation for multiple languages\n"
        "   - Version compatibility built-in\n\n"
        "Example .proto file:\n"
        "```protobuf\n"
        "syntax = \"proto3\";\n\n"
        "service UserService {\n"
        "    rpc GetUser(GetUserRequest) returns (User);\n"
        "    rpc ListUsers(Empty) returns (stream User);\n"
        "}\n\n"
        "message User {\n"
        "    int64 id = 1;\n"
        "    string name = 2;\n"
        "    string email = 3;\n"
        "}\n"
        "```\n\n"
        "2024 Features:\n"
        "- gRPC-Web for browser support\n"
        "- Reflection API for dynamic discovery\n"
        "- Health checking protocol\n"
        "- Retry policies and deadlines\n\n"
        "When to use:\n"
        "- Internal microservice communication\n"
        "- High-throughput systems\n"
        "- Multi-language environments\n\n"
        "Industry usage: Google, Netflix, Square, Cisco use gRPC in production."
    },

    // Distributed Systems
    {
        "Consensus Algorithms: Raft vs Paxos",
        "Distributed Systems",
        DIFFICULTY_EXPERT,
        "Consensus algorithms allow distributed systems to agree on a value even with failures. Raft is the dominant choice in 2024.\n\n"
        "Raft Algorithm:\n\n"
        "1. Leader Election:\n"
        "   - Nodes start as followers\n"
        "   - Timeout triggers election\n"
        "   - Majority votes elect leader\n\n"
        "2. Log Replication:\n"
        "   - Leader receives writes\n"
        "   - Replicates to followers\n"
        "   - Commits when majority acknowledges\n\n"
        "3. Safety:\n"
        "   - Leader completeness: Committed entries never lost\n"
        "   - State machine safety: All nodes apply same commands\n\n"
        "Key Invariants:\n"
        "- Election safety: At most one leader per term\n"
        "- Log matching: If two logs contain entry with same index and term, they're identical up to that point\n\n"
        "2024 Implementations:\n"
        "- etcd (Kubernetes): Go Raft\n"
        "- Consul (HashiCorp): Go Raft\n"
        "- CockroachDB: Raft for replication\n"
        "- TiKV: Rust Raft\n\n"
        "Performance optimizations:\n"
        "- Pipeline replication (send next entry before ack)\n"
        "- Batch commits (reduce RTTs)\n"
        "- ReadIndex for linearizable reads without log entry\n\n"
        "When to use:\n"
        "- Configuration management (etcd)\n"
        "- Leader election\n"
        "- Distributed locking\n"
        "- Replicated state machines"
    },
    {
        "Event Sourcing and CQRS",
        "Distributed Systems",
        DIFFICULTY_ADVANCED,
        "Event Sourcing stores state as a sequence of events, enabling time travel, auditability, and scalability.\n\n"
        "Event Sourcing principles:\n\n"
        "1. Store events, not state:\n"
        "   - Append-only log of events\n"
        "   - Current state = replay all events\n"
        "   - Example: \"OrderCreated\", \"ItemAdded\", \"OrderShipped\"\n\n"
        "2. Events are immutable:\n"
        "   - Never delete or modify events\n"
        "   - Corrections are new events\n\n"
        "3. Multiple projections:\n"
        "   - Build different read models from same events\n"
        "   - Optimize for query patterns\n\n"
        "CQRS (Command Query Responsibility Segregation):\n"
        "- Separate write model (commands) from read model (queries)\n"
        "- Write: Validate and emit events\n"
        "- Read: Query materialized views\n\n"
        "Architecture (2024):\n"
        "```\n"
        "Commands -> Aggregate -> Events -> Event Store\n"
        "                                      |\n"
        "                                      v\n"
        "                                  Projections -> Read Models -> Queries\n"
        "```\n\n"
        "Benefits:\n"
        "- Complete audit log\n"
        "- Time travel (replay to any point)\n"
        "- Horizontal scaling (reads separate from writes)\n"
        "- Debugging (reproduce bugs by replaying events)\n\n"
        "Challenges:\n"
        "- Event versioning (use schema registry)\n"
        "- Eventual consistency (reads lag writes)\n"
        "- Snapshot optimization (avoid replaying millions of events)\n\n"
        "2024 Tools:\n"
        "- EventStoreDB (specialized event store)\n"
        "- Kafka (distributed log)\n"
        "- Axon Framework (Java CQRS)\n"
        "- Marten (PostgreSQL event store)"
    },
    {
        "Distributed Tracing with OpenTelemetry",
        "Distributed Systems",
        DIFFICULTY_INTERMEDIATE,
        "OpenTelemetry is the 2024 standard for distributed tracing, metrics, and logs in microservices.\n\n"
        "Why Distributed Tracing:\n"
        "- Request spans multiple services\n"
        "- Need to track latency across services\n"
        "- Identify bottlenecks and failures\n\n"
        "Core Concepts:\n\n"
        "1. Trace: End-to-end journey of a request\n"
        "2. Span: Single operation within a trace\n"
        "3. Context: Propagated across service boundaries\n\n"
        "Example in Go:\n"
        "```go\n"
        "import \"go.opentelemetry.io/otel\"\n\n"
        "tracer := otel.Tracer(\"my-service\")\n"
        "ctx, span := tracer.Start(ctx, \"process_request\")\n"
        "defer span.End()\n\n"
        "// Add attributes\n"
        "span.SetAttributes(\n"
        "    attribute.String(\"user.id\", userID),\n"
        "    attribute.Int(\"items.count\", len(items)),\n"
        ")\n\n"
        "// Propagate context to next service\n"
        "req = req.WithContext(ctx)\n"
        "```\n\n"
        "Context Propagation:\n"
        "- W3C Trace Context (traceparent header)\n"
        "- Format: `00-{trace-id}-{span-id}-{flags}`\n"
        "- Automatically injected by SDKs\n\n"
        "2024 Backend Options:\n"
        "- Jaeger (CNCF, open source)\n"
        "- Tempo (Grafana, cost-efficient)\n"
        "- Honeycomb (commercial, powerful querying)\n"
        "- DataDog APM (full observability platform)\n\n"
        "Best Practices:\n"
        "- Sample high-traffic endpoints (1-10%)\n"
        "- Always trace errors (100%)\n"
        "- Add semantic attributes (user.id, http.status_code)\n"
        "- Use tail-based sampling for rare errors"
    },
    {
        "Consistent Hashing for Load Distribution",
        "Distributed Systems",
        DIFFICULTY_INTERMEDIATE,
        "Consistent hashing enables efficient load distribution with minimal reshuffling when nodes are added or removed.\n\n"
        "Problem with Naive Hashing:\n"
        "- hash(key) % N maps keys to nodes\n"
        "- Adding/removing a node remaps almost all keys\n"
        "- Expensive cache invalidation\n\n"
        "Consistent Hashing Solution:\n\n"
        "1. Hash space: 0 to 2^32-1 (or 2^64-1)\n"
        "2. Hash nodes onto ring\n"
        "3. Hash keys onto same ring\n"
        "4. Key goes to next node clockwise\n\n"
        "Virtual Nodes:\n"
        "- Each physical node has multiple positions\n"
        "- Better load distribution\n"
        "- Typically 100-200 virtual nodes per physical node\n\n"
        "Implementation:\n"
        "```c\n"
        "typedef struct {\n"
        "    uint32_t hash;\n"
        "    char node[64];\n"
        "} VirtualNode;\n\n"
        "VirtualNode ring[NUM_NODES * VIRTUAL_NODES];\n\n"
        "const char* find_node(const char *key) {\n"
        "    uint32_t key_hash = hash_function(key);\n"
        "    \n"
        "    // Binary search for next node\n"
        "    int left = 0, right = num_vnodes - 1;\n"
        "    while (left < right) {\n"
        "        int mid = (left + right) / 2;\n"
        "        if (ring[mid].hash < key_hash)\n"
        "            left = mid + 1;\n"
        "        else\n"
        "            right = mid;\n"
        "    }\n"
        "    \n"
        "    return ring[left].node;\n"
        "}\n"
        "```\n\n"
        "Benefits:\n"
        "- Adding node: Only 1/N keys remapped\n"
        "- Removing node: Affected keys redistributed evenly\n"
        "- Used in: DynamoDB, Cassandra, Riak, Chord DHT\n\n"
        "2024 Evolution: Rendezvous hashing (HRW) for weighted nodes and better uniformity."
    },

    // Modern Language Features
    {
        "Rust Async/Await and Tokio Runtime",
        "Modern Languages - Rust",
        DIFFICULTY_ADVANCED,
        "Rust's async/await provides zero-cost abstractions for concurrent I/O without runtime overhead.\n\n"
        "Async Model:\n\n"
        "1. Futures are lazy:\n"
        "   ```rust\n"
        "   async fn fetch_data() -> String {\n"
        "       // Does nothing until .awaited\n"
        "   }\n"
        "   ```\n\n"
        "2. No implicit runtime:\n"
        "   - Choose runtime (Tokio, async-std, smol)\n"
        "   - Different trade-offs (throughput vs latency)\n\n"
        "3. Zero-cost abstraction:\n"
        "   - Compiles to state machine\n"
        "   - No heap allocation per task\n"
        "   - No GC pauses\n\n"
        "Tokio Runtime (2024):\n"
        "```rust\n"
        "#[tokio::main]\n"
        "async fn main() {\n"
        "    // Multi-threaded runtime\n"
        "    let result = tokio::spawn(async {\n"
        "        // Work-stealing scheduler\n"
        "        process_data().await\n"
        "    }).await.unwrap();\n"
        "}\n"
        "```\n\n"
        "Key Features:\n"
        "- Work-stealing scheduler (Go-style)\n"
        "- io_uring support on Linux\n"
        "- IOCP on Windows\n"
        "- Instrumentation with tokio-console\n\n"
        "Performance (2024):\n"
        "- 1M+ concurrent connections on single machine\n"
        "- <1µs task spawn overhead\n"
        "- Zero copy with bytes crate\n\n"
        "Comparison with Go:\n"
        "- Rust: Explicit async, zero runtime cost\n"
        "- Go: Implicit goroutines, GC overhead\n"
        "- Rust wins on latency, Go wins on simplicity\n\n"
        "Best practices:\n"
        "- Avoid blocking in async (use spawn_blocking)\n"
        "- Use select! for multiple futures\n"
        "- Pin<Box<>> for self-referential structs"
    },
    {
        "Go Generics: Type Parameters in Practice",
        "Modern Languages - Go",
        DIFFICULTY_INTERMEDIATE,
        "Go 1.18 (2022) introduced generics, and by 2024 they're widely adopted for type-safe, reusable code.\n\n"
        "Basic Syntax:\n"
        "```go\n"
        "func Max[T constraints.Ordered](a, b T) T {\n"
        "    if a > b {\n"
        "        return a\n"
        "    }\n"
        "    return b\n"
        "}\n\n"
        "result := Max(10, 20)        // int\n"
        "result := Max(1.5, 2.5)      // float64\n"
        "result := Max(\"a\", \"b\")      // string\n"
        "```\n\n"
        "Type Constraints:\n"
        "```go\n"
        "// Custom constraint\n"
        "type Numeric interface {\n"
        "    ~int | ~int64 | ~float64\n"
        "}\n\n"
        "func Sum[T Numeric](nums []T) T {\n"
        "    var total T\n"
        "    for _, n := range nums {\n"
        "        total += n\n"
        "    }\n"
        "    return total\n"
        "}\n"
        "```\n\n"
        "Generic Data Structures:\n"
        "```go\n"
        "type Stack[T any] struct {\n"
        "    items []T\n"
        "}\n\n"
        "func (s *Stack[T]) Push(item T) {\n"
        "    s.items = append(s.items, item)\n"
        "}\n\n"
        "func (s *Stack[T]) Pop() (T, bool) {\n"
        "    if len(s.items) == 0 {\n"
        "        var zero T\n"
        "        return zero, false\n"
        "    }\n"
        "    item := s.items[len(s.items)-1]\n"
        "    s.items = s.items[:len(s.items)-1]\n"
        "    return item, true\n"
        "}\n"
        "```\n\n"
        "2024 Standard Library Usage:\n"
        "- slices.Sort[T comparable]()\n"
        "- maps.Keys[K comparable, V any]()\n"
        "- sync.Map with type-safe wrappers\n\n"
        "Performance:\n"
        "- Monomorphization at compile time\n"
        "- No runtime overhead vs interface{}\n"
        "- Better compiler optimizations\n\n"
        "When to use:\n"
        "- Data structures (stacks, queues, trees)\n"
        "- Algorithms (sort, search, map/reduce)\n"
        "- Avoid overuse: interfaces often better"
    },
    {
        "C++20 Concepts and Coroutines",
        "Modern Languages - C++",
        DIFFICULTY_ADVANCED,
        "C++20 introduced concepts for compile-time constraints and coroutines for async programming.\n\n"
        "Concepts:\n\n"
        "Replace SFINAE with readable constraints:\n"
        "```cpp\n"
        "// Old way (SFINAE)\n"
        "template<typename T>\n"
        "typename std::enable_if<std::is_integral<T>::value, T>::type\n"
        "add(T a, T b) { return a + b; }\n\n"
        "// C++20 way (Concepts)\n"
        "template<std::integral T>\n"
        "T add(T a, T b) { return a + b; }\n"
        "```\n\n"
        "Custom Concepts:\n"
        "```cpp\n"
        "template<typename T>\n"
        "concept Hashable = requires(T a) {\n"
        "    { std::hash<T>{}(a) } -> std::convertible_to<std::size_t>;\n"
        "};\n\n"
        "template<Hashable T>\n"
        "class HashTable {\n"
        "    // T must be hashable\n"
        "};\n"
        "```\n\n"
        "Coroutines:\n\n"
        "Cooperative multitasking without callbacks:\n"
        "```cpp\n"
        "generator<int> fibonacci() {\n"
        "    int a = 0, b = 1;\n"
        "    while (true) {\n"
        "        co_yield a;\n"
        "        auto next = a + b;\n"
        "        a = b;\n"
        "        b = next;\n"
        "    }\n"
        "}\n\n"
        "for (int n : fibonacci() | std::views::take(10)) {\n"
        "    std::cout << n << ' ';\n"
        "}\n"
        "```\n\n"
        "Async Coroutines:\n"
        "```cpp\n"
        "task<std::string> fetch_data(const std::string& url) {\n"
        "    auto response = co_await http_get(url);\n"
        "    co_return response.body();\n"
        "}\n\n"
        "task<void> process() {\n"
        "    auto data = co_await fetch_data(\"https://api.example.com\");\n"
        "    std::cout << data << '\\n';\n"
        "}\n"
        "```\n\n"
        "2024 Libraries:\n"
        "- cppcoro (Lewis Baker)\n"
        "- Boost.Asio with C++20 coroutines\n"
        "- folly::coro (Facebook)\n\n"
        "Benefits:\n"
        "- Better error messages with concepts\n"
        "- Cleaner async code with coroutines\n"
        "- Zero-overhead abstractions\n\n"
        "Adoption: C++20 is standard in 2024, all major compilers support it."
    },
    {
        "Zig: Manual Memory Management Done Right",
        "Modern Languages - Zig",
        DIFFICULTY_INTERMEDIATE,
        "Zig is a modern systems language (2024) that prioritizes simplicity and explicit control over memory.\n\n"
        "Key Philosophy:\n\n"
        "1. No Hidden Control Flow:\n"
        "   - No exceptions (use error unions)\n"
        "   - No async by default\n"
        "   - No operator overloading\n\n"
        "2. Explicit Allocators:\n"
        "   ```zig\n"
        "   const std = @import(\"std\");\n"
        "   \n"
        "   pub fn main() !void {\n"
        "       var gpa = std.heap.GeneralPurposeAllocator(.{}){};\n"
        "       defer _ = gpa.deinit();\n"
        "       \n"
        "       const allocator = gpa.allocator();\n"
        "       const list = try allocator.alloc(i32, 10);\n"
        "       defer allocator.free(list);\n"
        "   }\n"
        "   ```\n\n"
        "3. Comptime (compile-time execution):\n"
        "   ```zig\n"
        "   fn max(comptime T: type, a: T, b: T) T {\n"
        "       return if (a > b) a else b;\n"
        "   }\n"
        "   \n"
        "   // Generic, but monomorphized at compile time\n"
        "   const result = max(i32, 10, 20);\n"
        "   ```\n\n"
        "Error Handling:\n"
        "```zig\n"
        "const File = struct {\n"
        "    fn open(path: []const u8) !File {\n"
        "        // Returns File or error\n"
        "        return error.FileNotFound;\n"
        "    }\n"
        "};\n\n"
        "pub fn main() !void {\n"
        "    const file = try File.open(\"data.txt\");\n"
        "    // Handle error or continue\n"
        "}\n"
        "```\n\n"
        "C Interop:\n"
        "```zig\n"
        "const c = @cImport({\n"
        "    @cInclude(\"stdio.h\");\n"
        "});\n\n"
        "pub fn main() void {\n"
        "    _ = c.printf(\"Hello from Zig!\\n\");\n"
        "}\n"
        "```\n\n"
        "2024 Advantages:\n"
        "- Faster compile times than Rust\n"
        "- Better C interop than Rust\n"
        "- No LLVM bloat (custom backend planned)\n"
        "- Used in: Bun (JavaScript runtime), TigerBeetle (database)\n\n"
        "When to choose Zig:\n"
        "- Need C interop\n"
        "- Prefer explicit over implicit\n"
        "- Want faster iteration (compile times)"
    },

    // Performance Optimization
    {
        "SIMD Programming with AVX-512",
        "Performance Optimization",
        DIFFICULTY_EXPERT,
        "SIMD (Single Instruction Multiple Data) enables processing multiple data elements in parallel using specialized CPU instructions.\n\n"
        "AVX-512 (2024 Intel/AMD CPUs):\n"
        "- 512-bit vectors (16 x 32-bit or 8 x 64-bit)\n"
        "- Mask registers for conditional operations\n"
        "- Fused multiply-add (FMA)\n\n"
        "Example: Vector addition\n"
        "```c\n"
        "#include <immintrin.h>\n\n"
        "void add_vectors_avx512(float *a, float *b, float *c, size_t n) {\n"
        "    size_t i = 0;\n"
        "    \n"
        "    // Process 16 floats at a time\n"
        "    for (; i + 16 <= n; i += 16) {\n"
        "        __m512 va = _mm512_loadu_ps(&a[i]);\n"
        "        __m512 vb = _mm512_loadu_ps(&b[i]);\n"
        "        __m512 vc = _mm512_add_ps(va, vb);\n"
        "        _mm512_storeu_ps(&c[i], vc);\n"
        "    }\n"
        "    \n"
        "    // Handle remainder\n"
        "    for (; i < n; i++) {\n"
        "        c[i] = a[i] + b[i];\n"
        "    }\n"
        "}\n"
        "```\n\n"
        "Speedup: 8-16x vs scalar code\n\n"
        "Conditional Operations with Masks:\n"
        "```c\n"
        "// Set negative values to zero\n"
        "__m512 v = _mm512_loadu_ps(data);\n"
        "__m512 zero = _mm512_setzero_ps();\n"
        "__mmask16 mask = _mm512_cmp_ps_mask(v, zero, _CMP_LT_OS);\n"
        "v = _mm512_mask_mov_ps(v, mask, zero);\n"
        "```\n\n"
        "Auto-vectorization:\n"
        "- GCC/Clang can auto-vectorize simple loops\n"
        "- Use `-march=native -O3 -ftree-vectorize`\n"
        "- Check with `-fopt-info-vec-optimized`\n\n"
        "2024 Best Practices:\n"
        "- Align data to 64 bytes: `__attribute__((aligned(64)))`\n"
        "- Use `_mm_prefetch()` for memory-bound code\n"
        "- Profile with `perf stat -e fp_arith_inst_retired.512b_packed_single`\n"
        "- Beware of AVX-512 downclocking on some CPUs\n\n"
        "Libraries:\n"
        "- Intel IPP (Integrated Performance Primitives)\n"
        "- Agner Fog's VCL (Vector Class Library)\n"
        "- Highway (Google, portable SIMD)"
    },
    {
        "Lock-Free Data Structures",
        "Performance Optimization",
        DIFFICULTY_EXPERT,
        "Lock-free programming uses atomic operations to achieve thread safety without locks, eliminating contention.\n\n"
        "Compare-and-Swap (CAS):\n\n"
        "Fundamental primitive for lock-free algorithms:\n"
        "```c\n"
        "bool compare_exchange_weak(\n"
        "    atomic<T>* obj,\n"
        "    T* expected,\n"
        "    T desired\n"
        ") {\n"
        "    if (*obj == *expected) {\n"
        "        *obj = desired;\n"
        "        return true;\n"
        "    } else {\n"
        "        *expected = *obj;\n"
        "        return false;\n"
        "    }\n"
        "}\n"
        "```\n\n"
        "Lock-Free Stack:\n"
        "```c\n"
        "typedef struct Node {\n"
        "    int value;\n"
        "    struct Node *next;\n"
        "} Node;\n\n"
        "typedef struct {\n"
        "    _Atomic(Node*) head;\n"
        "} LockFreeStack;\n\n"
        "void push(LockFreeStack *stack, int value) {\n"
        "    Node *new_node = malloc(sizeof(Node));\n"
        "    new_node->value = value;\n"
        "    \n"
        "    Node *old_head;\n"
        "    do {\n"
        "        old_head = atomic_load(&stack->head);\n"
        "        new_node->next = old_head;\n"
        "    } while (!atomic_compare_exchange_weak(\n"
        "        &stack->head, &old_head, new_node));\n"
        "}\n\n"
        "bool pop(LockFreeStack *stack, int *value) {\n"
        "    Node *old_head;\n"
        "    do {\n"
        "        old_head = atomic_load(&stack->head);\n"
        "        if (old_head == NULL) return false;\n"
        "    } while (!atomic_compare_exchange_weak(\n"
        "        &stack->head, &old_head, old_head->next));\n"
        "    \n"
        "    *value = old_head->value;\n"
        "    // WARNING: Deferred reclamation needed (see below)\n"
        "    free(old_head);\n"
        "    return true;\n"
        "}\n"
        "```\n\n"
        "ABA Problem:\n"
        "- Thread A reads head (A)\n"
        "- Thread B pops A, pops B, pushes A\n"
        "- Thread A's CAS succeeds, but state changed\n\n"
        "Solution: Tagged pointers or Hazard Pointers\n\n"
        "2024 Memory Reclamation:\n"
        "- Epoch-Based Reclamation (crossbeam-epoch in Rust)\n"
        "- Hazard Pointers (Facebook's folly)\n"
        "- Quiescent-State-Based Reclamation (RCU in Linux)\n\n"
        "Performance:\n"
        "- 2-10x faster than locks for high contention\n"
        "- Guaranteed progress (lock-free property)\n"
        "- No deadlocks, priority inversion\n\n"
        "When to use:\n"
        "- High contention scenarios\n"
        "- Real-time systems (bounded latency)\n"
        "- Consider: Complexity vs benefit trade-off"
    },
    {
        "Memory Allocator Design",
        "Performance Optimization",
        DIFFICULTY_EXPERT,
        "Custom memory allocators can dramatically improve performance for specific workload patterns.\n\n"
        "malloc/free problems:\n"
        "- General-purpose = slow for specific patterns\n"
        "- Lock contention in multithreaded code\n"
        "- Fragmentation over time\n\n"
        "Allocator Strategies (2024):\n\n"
        "1. Arena/Region Allocator:\n"
        "```c\n"
        "typedef struct {\n"
        "    char *base;\n"
        "    size_t size;\n"
        "    size_t offset;\n"
        "} Arena;\n\n"
        "void* arena_alloc(Arena *arena, size_t size) {\n"
        "    // Align to 8 bytes\n"
        "    size = (size + 7) & ~7;\n"
        "    \n"
        "    if (arena->offset + size > arena->size)\n"
        "        return NULL;\n"
        "    \n"
        "    void *ptr = arena->base + arena->offset;\n"
        "    arena->offset += size;\n"
        "    return ptr;\n"
        "}\n\n"
        "void arena_reset(Arena *arena) {\n"
        "    arena->offset = 0; // Deallocate all at once\n"
        "}\n"
        "```\n\n"
        "Use case: Request handlers, parsers (allocate, process, free all)\n"
        "Speedup: 10-100x vs malloc/free\n\n"
        "2. Pool Allocator:\n"
        "```c\n"
        "typedef struct FreeNode {\n"
        "    struct FreeNode *next;\n"
        "} FreeNode;\n\n"
        "typedef struct {\n"
        "    void *memory;\n"
        "    FreeNode *free_list;\n"
        "    size_t chunk_size;\n"
        "} Pool;\n\n"
        "void* pool_alloc(Pool *pool) {\n"
        "    if (pool->free_list == NULL) return NULL;\n"
        "    \n"
        "    void *ptr = pool->free_list;\n"
        "    pool->free_list = pool->free_list->next;\n"
        "    return ptr;\n"
        "}\n\n"
        "void pool_free(Pool *pool, void *ptr) {\n"
        "    FreeNode *node = ptr;\n"
        "    node->next = pool->free_list;\n"
        "    pool->free_list = node;\n"
        "}\n"
        "```\n\n"
        "Use case: Fixed-size objects (network packets, AST nodes)\n"
        "Benefits: O(1) alloc/free, no fragmentation\n\n"
        "3. Thread-Caching Allocator (mimalloc, jemalloc):\n"
        "- Per-thread caches eliminate lock contention\n"
        "- Size classes reduce fragmentation\n"
        "- Used by: Microsoft, Facebook, FreeBSD\n\n"
        "2024 Modern Allocators:\n"
        "- mimalloc (Microsoft): Fastest general-purpose\n"
        "- jemalloc (Facebook): Good for large servers\n"
        "- snmalloc (Microsoft): Lock-free message passing\n"
        "- rpmalloc: Game engine standard\n\n"
        "Benchmarking:\n"
        "```bash\n"
        "LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libmimalloc.so ./myapp\n"
        "```\n\n"
        "When to customize:\n"
        "- Profiling shows malloc in top 10\n"
        "- Clear allocation patterns\n"
        "- Need deterministic performance"
    },
    {
        "CPU Cache Optimization Techniques",
        "Performance Optimization",
        DIFFICULTY_ADVANCED,
        "Understanding CPU caches is critical for high-performance code in 2024.\n\n"
        "Modern CPU Cache Hierarchy:\n"
        "```\n"
        "L1: 32-64 KB, 4 cycles, per-core\n"
        "L2: 256-512 KB, 12 cycles, per-core\n"
        "L3: 8-64 MB, 40 cycles, shared\n"
        "RAM: GBs, 200+ cycles\n"
        "```\n\n"
        "Cache Line Size: 64 bytes (critical!)\n\n"
        "Optimization Techniques:\n\n"
        "1. Structure Packing:\n"
        "```c\n"
        "// Bad: 24 bytes, cache line waste\n"
        "struct Bad {\n"
        "    char c;      // 1 byte + 7 padding\n"
        "    long long l; // 8 bytes\n"
        "    int i;       // 4 bytes + 4 padding\n"
        "};\n\n"
        "// Good: 16 bytes\n"
        "struct Good {\n"
        "    long long l; // 8 bytes\n"
        "    int i;       // 4 bytes\n"
        "    char c;      // 1 byte + 3 padding\n"
        "};\n"
        "```\n\n"
        "2. False Sharing Prevention:\n"
        "```c\n"
        "// Bad: Threads contend on same cache line\n"
        "struct Counter {\n"
        "    long count1; // Thread 1\n"
        "    long count2; // Thread 2 - same cache line!\n"
        "};\n\n"
        "// Good: Pad to separate cache lines\n"
        "struct Counter {\n"
        "    long count1;\n"
        "    char pad[64 - sizeof(long)];\n"
        "    long count2;\n"
        "};\n"
        "```\n\n"
        "3. Array of Structures vs Structure of Arrays:\n"
        "```c\n"
        "// AoS: Poor cache locality for position-only access\n"
        "struct Particle { float x, y, z; float vx, vy, vz; };\n"
        "Particle particles[1000];\n\n"
        "// SoA: Better cache locality\n"
        "struct Particles {\n"
        "    float x[1000], y[1000], z[1000];\n"
        "    float vx[1000], vy[1000], vz[1000];\n"
        "};\n"
        "```\n\n"
        "4. Loop Blocking (Tiling):\n"
        "```c\n"
        "// Cache-friendly matrix multiply\n"
        "for (int ii = 0; ii < N; ii += BLOCK) {\n"
        "    for (int jj = 0; jj < N; jj += BLOCK) {\n"
        "        for (int kk = 0; kk < N; kk += BLOCK) {\n"
        "            // Process BLOCK x BLOCK submatrix\n"
        "            for (int i = ii; i < ii + BLOCK; i++)\n"
        "                for (int j = jj; j < jj + BLOCK; j++)\n"
        "                    for (int k = kk; k < kk + BLOCK; k++)\n"
        "                        C[i][j] += A[i][k] * B[k][j];\n"
        "        }\n"
        "    }\n"
        "}\n"
        "```\n\n"
        "5. Prefetching:\n"
        "```c\n"
        "#include <xmmintrin.h>\n\n"
        "for (int i = 0; i < n; i++) {\n"
        "    _mm_prefetch(&data[i + 8], _MM_HINT_T0); // Prefetch ahead\n"
        "    process(data[i]);\n"
        "}\n"
        "```\n\n"
        "2024 Tools:\n"
        "- perf stat -e cache-misses,cache-references\n"
        "- valgrind --tool=cachegrind\n"
        "- Intel VTune for detailed analysis\n\n"
        "Impact: Cache optimization can yield 2-10x speedups"
    },
};

int insert_lesson(sqlite3 *db, const LessonData *lesson) {
    const char *sql = "INSERT INTO lessons (topic, category, difficulty, content, timestamp) "
                      "VALUES (?, ?, ?, ?, ?);";

    sqlite3_stmt *stmt;
    int rc = sqlite3_prepare_v2(db, sql, -1, &stmt, NULL);

    if (rc != SQLITE_OK) {
        fprintf(stderr, "Failed to prepare statement: %s\n", sqlite3_errmsg(db));
        return rc;
    }

    time_t now = time(NULL);

    sqlite3_bind_text(stmt, 1, lesson->topic, -1, SQLITE_STATIC);
    sqlite3_bind_text(stmt, 2, lesson->category, -1, SQLITE_STATIC);
    sqlite3_bind_int(stmt, 3, lesson->difficulty);
    sqlite3_bind_text(stmt, 4, lesson->content, -1, SQLITE_STATIC);
    sqlite3_bind_int64(stmt, 5, now);

    rc = sqlite3_step(stmt);

    if (rc != SQLITE_DONE) {
        fprintf(stderr, "Execution failed: %s\n", sqlite3_errmsg(db));
        sqlite3_finalize(stmt);
        return rc;
    }

    sqlite3_finalize(stmt);
    return SQLITE_OK;
}

int main() {
    sqlite3 *db;
    int rc = init_database(&db);

    if (rc != SQLITE_OK) {
        fprintf(stderr, "Failed to initialize database.\n");
        return 1;
    }

    printf("Seeding database with %zu lessons...\n", sizeof(lessons) / sizeof(lessons[0]));

    int success_count = 0;
    int fail_count = 0;

    for (size_t i = 0; i < sizeof(lessons) / sizeof(lessons[0]); i++) {
        rc = insert_lesson(db, &lessons[i]);
        if (rc == SQLITE_OK) {
            success_count++;
            printf("✓ Added: %s\n", lessons[i].topic);
        } else {
            fail_count++;
            printf("✗ Failed: %s\n", lessons[i].topic);
        }
    }

    printf("\n=== Seeding Complete ===\n");
    printf("Successfully added: %d lessons\n", success_count);
    printf("Failed: %d lessons\n", fail_count);
    printf("\nDatabase file: %s\n", DB_FILE);

    close_database(db);
    return 0;
}
